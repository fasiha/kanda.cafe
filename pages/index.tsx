import type { InferGetStaticPropsType, NextPage } from "next";
import { readFile, readdir } from "fs/promises";
import path from "path";
import { createElement, useEffect, useState } from "react";
import styles from "../styles/Home.module.css";

import {
  v1ResSentenceAnalyzed,
  Furigana,
  Xref,
  Word,
  Sense,
  ConjugatedPhrase,
  Particle,
} from "curtiz-japanese-nlp/interfaces";
import { AdjDeconjugated, Deconjugated } from "kamiya-codec";
import { ChinoParticle, ChinoParticlePicker, setup } from "../components/ChinoParticlePicker";
import { SimpleCharacter } from "curtiz-japanese-nlp/kanjidic";

export const getStaticProps = async () => {
  // might only print if you restart next dev server
  const parentDir = path.join(process.cwd(), "data");
  const jsons = (await readdir(parentDir)).filter((f) => f.toLowerCase().endsWith(".json"));
  console.log("ls", jsons);
  const sentences = await Promise.all(
    jsons.map((j) => readFile(path.join(parentDir, j), "utf8").then((x) => JSON.parse(x)))
  );
  const obj: SentenceDb = Object.fromEntries(sentences.map((s) => [s.sentence, s])); // TODO validate

  const particlesMarkdown = await readFile("all-about-particles.md", "utf8");
  const tags: NonNullable<v1ResSentenceAnalyzed["tags"]> = JSON.parse(await readFile("tags.json", "utf8"));
  return { props: { sentences: obj, particlesMarkdown, tags } };
};

interface FuriganaProps {
  vv: Furigana[][];
}
const Furigana = ({ vv }: FuriganaProps) => {
  return createElement(
    "span",
    null,
    ...vv.flatMap((v) =>
      v.map((f) =>
        typeof f === "string" ? (
          f
        ) : (
          <ruby>
            {f.ruby}
            <rt>{f.rt}</rt>
          </ruby>
        )
      )
    )
  );
};

function renderKanji(w: Word) {
  return w.kanji.map((k) => k.text).join("„Éª");
}
function renderKana(w: Word) {
  return w.kana.map((k) => k.text).join("„Éª");
}
function printXrefs(v: Xref[]) {
  return v.map((x) => x.join(",")).join(";");
}
function renderSenses(w: Word, tags: Record<string, string>): string[] {
  type Tag = string;
  type TagKey = {
    [K in keyof Sense]: Sense[K] extends Tag[] ? K : never;
  }[keyof Sense];
  const tagFields: Partial<Record<TagKey, string>> = {
    dialect: "üó£",
    field: "üÄÑÔ∏è",
    misc: "‚úã",
  };
  return w.sense.map(
    (sense, n) =>
      sense.gloss.map((gloss) => gloss.text).join("/") +
      (sense.related.length ? ` (üëâ ${printXrefs(sense.related)})` : "") +
      (sense.antonym.length ? ` (üëà ${printXrefs(sense.antonym)})` : "") +
      Object.entries(tagFields)
        .map(([k, v]) =>
          sense[k as TagKey].length ? ` (${v} ${sense[k as TagKey].map((k) => tags[k]).join("; ")})` : ""
        )
        .join("")
  );
}
function range(start: number, endExclusive: number, step = 1) {
  const ret: number[] = [];
  if (step === 0) {
    return ret;
  } else if (step > 0) {
    for (let i = start; i < endExclusive; i += step) {
      ret.push(i);
    }
  } else {
    for (let i = start; i > endExclusive; i += step) {
      ret.push(i);
    }
  }
  return ret;
}
function upsertIfNew<X, Y>(v: X[], newx: X, key: (x: X) => Y) {
  const newy = key(newx);
  for (const [i, x] of v.entries()) {
    const y = key(x);
    if (y === newy) {
      if (x === newx) {
        return v;
      }
      const copy = v.slice();
      copy[i] = newx;
      return copy;
    }
  }
  return v.concat(newx);
}
function circleNumber(n: number): string {
  const circledNumbers = "‚ë†‚ë°‚ë¢‚ë£‚ë§‚ë•‚ë¶‚ëß‚ë®‚ë©‚ë™‚ë´‚ë¨‚ë≠‚ëÆ‚ëØ‚ë∞‚ë±‚ë≤‚ë≥„âë„âí„âì„âî„âï„âñ„âó„âò„âô„âö„âõ„âú„âù„âû„âü„ä±„ä≤„ä≥„ä¥„äµ„ä∂„ä∑„ä∏„äπ„ä∫„äª„äº„äΩ„äæ„äø";
  return circledNumbers[n] || "" + n;
}

function renderDeconjugation(d: AdjDeconjugated | Deconjugated) {
  if ("auxiliaries" in d) {
    return `${d.auxiliaries.join(" + ")} + ${d.conjugation}`;
  }
  return d.conjugation;
}

interface Hit {
  startIdx: number;
  endIdx: number;
  word: Word;
  sense: number;
}

const clozeToKey = (x: Pick<ConjugatedPhrase, "startIdx" | "endIdx">): string => `${x.startIdx}-${x.endIdx}`;

type AnnotatedConjugatedPhrase = ConjugatedPhrase & { selectedDeconj: ConjugatedPhrase["deconj"][0] };
type AnnotatedParticle = Particle & { chinoTag: string };
interface DependencyTree {
  tree: Record<number, number[]>;
  nodes: { idx: number; startMorphemeIdx: number; endMorphemeIdx: number }[];
}
interface SentenceDbEntry {
  furigana: Furigana[][];
  dictHits: Hit[];
  conjHits: AnnotatedConjugatedPhrase[];
  particles: AnnotatedParticle[];
  kanjidic: v1ResSentenceAnalyzed["kanjidic"];
}
type SentenceDb = Record<string, { data: SentenceDbEntry }>;

const makeEmptyDependencyTree = (): DependencyTree => ({ tree: {}, nodes: [] });
function bunsetsuToDependencyTree(bunsetsus: v1ResSentenceAnalyzed["bunsetsus"]): DependencyTree {
  const ret = makeEmptyDependencyTree();
  let startMorphemeIdx = 0;
  for (const { idx, morphemes, parent } of bunsetsus) {
    ret.nodes.push({ idx, startMorphemeIdx, endMorphemeIdx: startMorphemeIdx + morphemes.length });
    ret.tree[parent] = (ret.tree[parent] || []).concat(idx);
    startMorphemeIdx += morphemes.length;
  }
  return ret;
}
interface JdeppProps {
  depTree: DependencyTree;
  furigana: Furigana[][];
  rootIdx?: number;
}
function Jdepp({ depTree, furigana, rootIdx = -1 }: JdeppProps) {
  const { tree, nodes } = depTree;
  const node = nodes.find((n) => n.idx === rootIdx);
  const f = node ? furigana.slice(node.startMorphemeIdx, node.endMorphemeIdx) : [];

  console.log({ tree, nodes });
  // return <></>;

  if (rootIdx in tree) {
    // non-leaf nodes
    if (!node) {
      // root
      return (
        <div className="dep-tree-root">
          {tree[rootIdx].map((r) => (
            <Jdepp depTree={depTree} furigana={furigana} rootIdx={r} />
          ))}
        </div>
      );
    }
    return (
      <div className="dep-tree-node">
        {tree[-1].map((r) => (
          <Jdepp depTree={depTree} furigana={furigana} rootIdx={r} />
        ))}
        <Furigana vv={f} />
      </div>
    );
  }
  // leaf
  if (node) {
    return (
      <div className="dep-tree-node">
        <Furigana vv={f} />
      </div>
    );
  }
  throw new Error("?");
}

interface AnnotateProps {
  line: string;
  sentencesDb: SentenceDb;
}
// This should not work in static-generated output, ideally it won't exist.
const HELPER_URL = "http://localhost:3010";
const Annotate = ({ line, sentencesDb }: AnnotateProps) => {
  // This component will be called for lines that haven't been annotated yet.

  const [nlp, setNlp] = useState<v1ResSentenceAnalyzed | undefined>(undefined);
  const [furigana, setFurigana] = useState<Furigana[][]>(sentencesDb[line]?.data?.furigana || []);
  const [dictHits, setDictHits] = useState<Hit[]>(sentencesDb[line]?.data?.dictHits || []);
  const [conjHits, setConjHits] = useState<AnnotatedConjugatedPhrase[]>(sentencesDb[line]?.data?.conjHits || []);
  const [particles, setParticles] = useState<AnnotatedParticle[]>(sentencesDb[line]?.data?.particles || []);
  const [kanjidic, setKanjidic] = useState<undefined | SentenceDbEntry["kanjidic"]>(sentencesDb[line]?.data?.kanjidic);
  const [depTree, setDepTree] = useState(makeEmptyDependencyTree());
  const idxsCovered = new Set(dictHits.flatMap((o) => range(o.startIdx, o.endIdx)));

  useEffect(() => {
    // Yes this will run twice in dev mode, see
    // https://reactjs.org/blog/2022/03/29/react-v18.html#new-strict-mode-behaviors
    if (!nlp) {
      (async function parse() {
        const req = await fetch(`${HELPER_URL}/sentence/${line}`, {
          headers: { Accept: "application/json" },
        });
        const data: v1ResSentenceAnalyzed = await req.json();
        setNlp(data);
        setKanjidic(data.kanjidic);
        setDepTree(bunsetsuToDependencyTree(data.bunsetsus));
        console.log("nlp", data);
      })();
    }
  }, []);

  useEffect(() => {
    saveDb(line, { dictHits, conjHits, particles, furigana, kanjidic: kanjidic || {} });
  }, [dictHits, conjHits, particles, furigana, kanjidic]);

  if (!nlp) {
    return <h2 lang={"ja"}>{furigana.length ? <Furigana vv={furigana} /> : line}</h2>;
  }
  if (!nlp.tags || !nlp.clozes) {
    throw new Error("tags/clozes expected");
  }
  const { tags, clozes } = nlp;
  return (
    <div>
      <h2 lang={"ja"}>
        <Furigana vv={nlp.furigana} />
      </h2>
      <section>
        <Jdepp depTree={depTree} furigana={furigana} rootIdx={-1} />
      </section>
      {furigana.length && kanjidic !== undefined ? (
        <button
          onClick={() => {
            setFurigana([]);
            setKanjidic(undefined);
          }}
        >
          Delete furigana + kanji
        </button>
      ) : (
        <button
          onClick={() => {
            setFurigana(nlp.furigana);
            setKanjidic(nlp.kanjidic);
          }}
        >
          Approve furigana + kanji
        </button>
      )}
      <details open>
        <summary>All annotations</summary>
        <details open>
          <summary>Selected dictionary entries</summary>
          <ul>
            {dictHits.map((h) => (
              <li>
                {h.startIdx}-{h.endIdx}: {renderKanji(h.word)} „Äå{renderKana(h.word)}„Äç {circleNumber(h.sense)}{" "}
                {renderSenses(h.word, tags)[h.sense]}
              </li>
            ))}
          </ul>
        </details>
        <details open>
          <summary>All conjugated phrases found</summary>
          <ol>
            {clozes.conjugatedPhrases.map((foundConj) => (
              <li>
                {foundConj.cloze.cloze} = <Furigana vv={[foundConj.lemmas[0]]} />{" "}
                {
                  <select
                    value={(function () {
                      const key = clozeToKey(foundConj);
                      const x = conjHits.find((dec) => clozeToKey(dec) === key)?.selectedDeconj;
                      if (!x) return "0";
                      const renderedX = renderDeconjugation(x);
                      return foundConj.deconj.findIndex((p) => renderDeconjugation(p) === renderedX) + 1;
                    })()}
                    onChange={(e) => {
                      const idx = +e.target.value;
                      const phraseKey = clozeToKey(foundConj);
                      setConjHits(
                        idx
                          ? upsertIfNew(
                              conjHits,
                              { ...foundConj, selectedDeconj: foundConj.deconj[idx - 1] },
                              clozeToKey
                            )
                          : conjHits.filter((p) => clozeToKey(p) !== phraseKey)
                      );
                    }}
                  >
                    <option value="0">Pick one of {foundConj.deconj.length}</option>
                    {foundConj.deconj.map((dec, idx) => {
                      const readable = renderDeconjugation(dec);
                      return (
                        <option key={idx + 1} value={idx + 1}>
                          {readable}
                        </option>
                      );
                    })}
                  </select>
                }
              </li>
            ))}
          </ol>
        </details>
        <details open>
          <summary>All particles found</summary>
          <ol>
            {clozes.particles.map((foundParticle) => {
              return (
                <li>
                  <sub>{foundParticle.cloze.left}</sub>
                  {foundParticle.cloze.cloze}
                  <sub>{foundParticle.cloze.right}</sub>:{" "}
                  {foundParticle.morphemes.map((m) => m.partOfSpeech.join("/")).join(", ")}{" "}
                  {foundParticle.chino.length && (
                    <ChinoParticlePicker
                      particleNumbers={foundParticle.chino.map(([i]) => i)}
                      currentValue={particles.find((x) => clozeToKey(foundParticle) === clozeToKey(x))?.chinoTag}
                      onChange={(e) =>
                        setParticles(
                          e
                            ? upsertIfNew(particles, { ...foundParticle, chinoTag: e }, clozeToKey)
                            : particles.filter((x) => clozeToKey(x) !== clozeToKey(foundParticle))
                        )
                      }
                    />
                  )}
                </li>
              );
            })}
          </ol>
        </details>
        <details open>
          <summary>All dictionary entries matched</summary>
          <ol>
            {nlp.hits.map(
              (scoreHits, outerIdx) =>
                scoreHits.results.length > 0 && (
                  <li key={outerIdx} value={outerIdx}>
                    <ol>
                      {scoreHits.results.map((res, innerIdx) => (
                        <li>
                          <details open={range(scoreHits.startIdx, res.endIdx).some((x) => !idxsCovered.has(x))}>
                            <summary>{typeof res.run === "string" ? res.run : res.run.cloze}</summary>
                            <ol>
                              {res.results.map((hit, wordIdx) => {
                                if (!hit.word) {
                                  throw new Error("word expected");
                                }
                                const word = hit.word;
                                return (
                                  <li>
                                    <sup>{hit.search}</sup> {renderKanji(hit.word)} „Äå{renderKana(hit.word)}„Äç (#
                                    {hit.word.id})
                                    <ol>
                                      {renderSenses(hit.word, tags).map((s, senseIdx) => (
                                        <li>
                                          <>
                                            {s}{" "}
                                            <button
                                              onClick={() => {
                                                setDictHits(
                                                  upsertIfNew(
                                                    dictHits,
                                                    {
                                                      startIdx: scoreHits.startIdx,
                                                      endIdx: res.endIdx,
                                                      word: word,
                                                      sense: senseIdx,
                                                    },
                                                    (x) => `${x.startIdx}/${x.endIdx}/${x.word.id}`
                                                  )
                                                );
                                              }}
                                            >
                                              Pick
                                            </button>
                                          </>
                                        </li>
                                      ))}
                                    </ol>
                                  </li>
                                );
                              })}
                            </ol>
                          </details>
                        </li>
                      ))}
                    </ol>
                  </li>
                )
            )}
          </ol>
        </details>
        {Object.keys(nlp.kanjidic).length ? (
          <details open>
            <summary>Kanji</summary>
            <Kanjidic hits={nlp.kanjidic} />
          </details>
        ) : (
          <></>
        )}
      </details>
    </div>
  );
};

interface RenderSentenceProps {
  line: string;
  sentencesDb: SentenceDb;
  tags: Record<string, string>;
  chinoMap: Map<string, ChinoParticle>;
}
const RenderSentence = ({ line, sentencesDb, tags, chinoMap }: RenderSentenceProps) => {
  const { furigana = [], dictHits = [], conjHits = [], particles = [], kanjidic = {} } = sentencesDb[line]?.data || {};
  const numKanji = Object.keys(kanjidic).length;
  const className = furigana.length === 0 ? "no-furigana" : "";
  return (
    <div>
      <h2 className={styles[className]} lang={"ja"}>
        {furigana.length ? <Furigana vv={furigana} /> : line}
      </h2>
      <ul>
        {dictHits.length ? (
          <li key="d">
            <ul>
              {dictHits.map((h) => (
                <li>
                  {h.startIdx}-{h.endIdx}: {renderKanji(h.word)} „Äå{renderKana(h.word)}„Äç {circleNumber(h.sense)}{" "}
                  {renderSenses(h.word, tags)[h.sense]}
                </li>
              ))}
            </ul>
          </li>
        ) : (
          <></>
        )}
        {conjHits.length ? (
          <li key="c">
            <ul>
              {conjHits.map((foundConj) => (
                <li>
                  {foundConj.cloze.cloze} = <Furigana vv={[foundConj.lemmas[0]]} />{" "}
                  {(function () {
                    const key = clozeToKey(foundConj);
                    const x = conjHits.find((dec) => clozeToKey(dec) === key)?.selectedDeconj;
                    if (!x) return "0";
                    const renderedX = renderDeconjugation(x);
                    const found = (foundConj.deconj as Ugh<typeof foundConj.deconj>).find(
                      (p) => renderDeconjugation(p) === renderedX
                    );
                    if (found) {
                      return renderDeconjugation(found);
                    }
                  })()}
                </li>
              ))}
            </ul>
          </li>
        ) : (
          <></>
        )}
        {particles.length ? (
          <li key="p">
            <ul>
              {particles.map((foundParticle) => {
                return (
                  <li>
                    <>
                      <sub>{foundParticle.cloze.left}</sub>
                      {foundParticle.cloze.cloze}
                      <sub>{foundParticle.cloze.right}</sub>:{" "}
                      {foundParticle.morphemes.map((m) => m.partOfSpeech.join("/")).join(", ")}{" "}
                      {foundParticle.chino.length &&
                        chinoMap.get(particles.find((x) => clozeToKey(foundParticle) === clozeToKey(x))?.chinoTag || "")
                          ?.fullLine}
                    </>
                  </li>
                );
              })}
            </ul>
          </li>
        ) : (
          <></>
        )}
        {numKanji ? (
          <li key="k">
            <details>
              <summary>{numKanji} kanji</summary>
              <Kanjidic hits={kanjidic} />
            </details>
          </li>
        ) : (
          <></>
        )}
      </ul>
    </div>
  );
};

interface KanjidicProps {
  hits: v1ResSentenceAnalyzed["kanjidic"];
}
function Kanjidic({ hits }: KanjidicProps) {
  return (
    <ul>
      {Object.values(hits).map((dic) => (
        <li>
          {renderKanjidicRoot(dic)}
          <ul>
            {dic.dependencies.map((root) => (
              <KanjidicChild root={root} />
            ))}
          </ul>
        </li>
      ))}
    </ul>
  );
}
interface KanjidicChildProps {
  root: v1ResSentenceAnalyzed["kanjidic"][string]["dependencies"][number];
}
function KanjidicChild({ root }: KanjidicChildProps) {
  if (!root.nodeMapped) {
    return <li>{root.node}</li>;
  }
  return (
    <li>
      {renderKanjidicRoot(root.nodeMapped)}
      <ul>
        {root.children.map((child) => (
          <KanjidicChild root={child} />
        ))}
      </ul>
    </li>
  );
}
function renderKanjidicRoot(k: SimpleCharacter) {
  const ret = `${k.literal} „Äå${k.readings.join("„Éª")}„Äç ${k.meanings.join("; ")}`;
  if (k.nanori.length) {
    return ret + ` (Âêç: ${k.nanori.join("„Éª")})`;
  }
  return ret;
}

async function saveDb(line: string, { dictHits, conjHits, particles, furigana, kanjidic }: SentenceDbEntry) {
  const post =
    dictHits.length > 0 ||
    conjHits.length > 0 ||
    particles.length > 0 ||
    furigana.length > 0 ||
    Object.keys(kanjidic).length > 0;
  const data: SentenceDbEntry = { dictHits, conjHits, particles, furigana, kanjidic };
  const res = await fetch(`${HELPER_URL}/sentence`, {
    method: post ? "POST" : "DELETE",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      sentence: line,
      data,
    }),
  });
  if (!res.ok) {
    console.error(`${res.status} ${res.statusText}`);
  } else {
    console.log("saved");
  }
}

// https://stackoverflow.com/questions/70843127#comment128628953_70843200
type Ugh<T> = (T extends (infer X)[] ? X : never)[];

export default function HomePage({
  sentences: sentencesDb,
  particlesMarkdown,
  tags,
}: InferGetStaticPropsType<typeof getStaticProps>) {
  const chinoMap = setup(particlesMarkdown).nestedMap;

  const [annotating, setAnnotating] = useState(new Set<string>());

  const s = (s: string) =>
    !annotating.has(s) ? (
      <>
        <RenderSentence key={s} line={s} sentencesDb={sentencesDb} tags={tags} chinoMap={chinoMap} />
        <button onClick={() => setAnnotating(new Set(annotating).add(s))}>Annotate above</button>
      </>
    ) : (
      <>
        <Annotate key={s} line={s} sentencesDb={sentencesDb} />
        <button onClick={() => setAnnotating(new Set([...annotating].filter((x) => x !== s)))}>Done annotating</button>
      </>
    );
  return (
    <div>
      <p>Here's the first line of Oshiri Tantei #3.</p>
      {s("„ÅÇ„ÇãÊó•„ÅÆÊúùÊó©„Åè„ÄÅ„Ç∏„É™„É™„É™„É≥„Å®„Åä„Åó„Çä„Åü„Çì„Å¶„ÅÑ‰∫ãÂãôÊâÄ„ÅÆÈõªË©±„ÅåÈ≥¥„Çä„Åæ„Åó„Åü„ÄÇ")}
      <p>And the second.</p>
      {s("„Éñ„É©„Ç¶„É≥„ÅØÁú†„ÅÑÁõÆ„Çí„Åì„Åô„Çä„Å™„Åå„ÇâÂèóË©±Âô®„ÇíÂèñ„Çä„Åæ„Åó„Åü")}
      {s("„Çè„Åó„Åò„ÇÉÔºÅ")}
      {s("‰ªä„Åô„Åê„ÉØ„É≥„Ç≥„É≠Ë≠¶ÂØüÁΩ≤„Å´Êù•„Å¶„Åè„Çå„Åü„Åæ„ÅàÔºÅ")}
      {s("„Åõ„Å£„Åã„Å°„Å™„Çì„Å†„Åã„Çâ")}
      <p>We're done with the first page! Page 3 in the book‚Äî</p>
      {s("„Éï„É†„ÄÅ„Å©„Å™„Åü„Åã„Çâ„Åß„Åó„Åü„ÅãÔºü")}
      {s("„Äå„Éû„É´„ÉÅ„Éº„Ç∫ÁΩ≤Èï∑„Åß„Åô„Äç")}
      {s("„Äå„ÉØ„É≥„Ç≥„É≠Ë≠¶ÂØüÁΩ≤„Åæ„ÅßÊù•„Å¶„Åè„Çå„Å£„Å¶„Äç„Åä„Åó„Çä„Åü„Çì„Å¶„ÅÑ„Å®„Éñ„É©„Ç¶„É≥„ÅØÊÄ•„ÅÑ„ÅßÂá∫„Åã„Åë„ÇãÊ∫ñÂÇô„Çí„Åó„Åæ„Åó„Åü")}
      <p>„Éù„Éï is SFX for his hat hitting his head.</p>
      <p>Onto page 4!!</p>
      {s("ÈöéÊÆµ„ÇíÈôç„Çä„Çã„Å®Èà¥„Åå„Äé„É©„ÉÉ„Ç≠„Éº„Ç≠„É£„ÉÉ„Éà„Äè„ÅÆÂâç„Åß„Éê„Ç§„ÇØ„ÇíÁ£®„ÅÑ„Å¶„ÅÑ„Åæ„Åó„Åü")}
      {s("„Äå„Åä„ÅØ„Çà„ÅÜ„ÄÇÊúù„Å£„Å±„Çâ„Åã„Çâ‰ªï‰∫ã„ÅãÔºü„Äç„Å®Èà¥„ÅåÂ∞ã„Å≠„Åæ„Åó„Åü")}
      {s("„Äå„ÉØ„É≥„Ç≥„É≠Ë≠¶ÂØüÁΩ≤„Å´Ë°å„Åè„Çì„Åß„Åô„ÄÇÊúù„ÅîÈ£Ø„ÇÇ„Åæ„Å†„Å†„Å£„Åü„ÅÆ„Å´„Äç")}
      {s("„Éñ„É©„Ç¶„É≥„ÅØÊ¨†‰º∏„Çí„Åó„Å™„Åå„ÇâÁ≠î„Åà„Åæ„Åó„Åü")}
      {s("„Åã„Å£„Åì„ÅÑ„ÅÑ„Éê„Ç§„ÇØ„Åß„Åô„Å≠")}
      {s("„Å†„ÇçÔºü„Éê„Ç§„ÉàÊéõ„ÅëÊåÅ„Å°„Åó„Å¶Ë≤∑„Å£„Åü„Çì„Å†")}
      <p>Page 5</p>
      {s("„Åä„Åó„Çä„Åü„Çì„Å¶„ÅÑ„Å®„Éñ„É©„Ç¶„É≥„ÅØ„ÉØ„É≥„Ç≥„É≠Ë≠¶ÂØüÁΩ≤„Å´ÁùÄ„Åç„Åæ„Åó„Åü")}
      {s("„Äå„ÅäÂæÖ„Å°„Åó„Å¶„Åä„Çä„Åæ„Åó„ÅüÔºÅ„Äç")}
      {s("„Ç¨„Çø„Ç§„ÅÆËâØ„ÅÑÂàë‰∫ã„Åü„Å°„ÅåÂá∫Ëøé„Åà„Åæ„Åô")}
      {s("„Åï„ÅÅ„ÄÅ„Åì„Å°„Çâ„Å∏„ÄÇ„Éû„É´„ÉÅ„Éº„Ç∫ÁΩ≤Èï∑„Åå„ÅäÂæÖ„Å°„Åß„Åô")}
      {s("ÔºìÂÄã„ÅÆ„Åä„Åó„Çä„ÇíÊé¢„Åõ")}
      {s("Â∏ÇÊ∞ë„ÅÆÂÆâÂÖ®")}
      <p>Picking up the pace, are we?</p>
      {s("Â§ß„Åç„ÅèÁ´ãÊ¥æ„Å™Êú∫„ÅÆÂâç„Å´„Éû„É´„ÉÅ„Éº„Ç∫ÁΩ≤Èï∑„Åå„Å°„Çá„Åì„Çì„Å®Â∫ß„Å£„Å¶„ÅÑ„Åæ„Åô")}
      {s("ÂæÖ„Å£„Å¶„Åä„Å£„Åü„ÅûÔºÅ")}
      {s("„Åä„Åó„Çä„Åü„Çì„Å¶„ÅÑ„Åè„Çì„ÄÇ„Éñ„É©„Ç¶„É≥„ÇÇ‰πÖ„Åó„Å∂„Çä„Åò„ÇÉ„Å™")}
      {s("„Äå„Éï„É†„ÄÅÊó©ÈÄü„ÅäÈõªË©±„Çí„Åä‰º∫„ÅÑ„Åó„Åæ„Åó„Çá„ÅÜ„Åã„Äç")}
      {s("Áä¨")}
      {s("„Çπ„Çø„ÉÉ")}
      {s("„Éñ„É©„ÉÉ„ÇØ„Ç∑„É£„Éâ„ÉºÂõ£„Å®„ÅÑ„ÅÜÈù¢ÂÄí„Å™Â•¥„Çâ„ÅåÁèæ„Çè„Çå„Å¶„Å™„ÄÇ")}
      {s("Ë´∏Âêõ„ÄÅË©≥„Åó„ÅÑË™¨Êòé„ÇíÈ†º„ÇÄ")}
      {s("„Éñ„É©„ÉÉ„ÇØ„Ç∑„É£„Éâ„ÉºÂõ£„ÅØÈõÜÂõ£„ÅßÁõó„Åø„ÇíË°å„ÅÜÁ™ÉÁõóÂõ£„Åß„ÅäÈáëÊåÅ„Å°„ÅÆÂÆ∂„ÇíÁãô„ÅÑ„ÄÅÂÆ∂„Å´„ÅÇ„ÇãÁâ©ÂÖ®„Å¶Ê†π„Åì„Åù„ÅéÁõó„Çì„Åß„ÅÑ„Åç„Åæ„Åô„ÄÇ")}
      <p>
        Learner's note: see Kamiya <em>Handbook of Japanese Verbs</em>, page 54, for more on the "Vconj + Vconj + masu"
        form.
      </p>
      {s("„É°„É≥„Éê„Éº„ÅØÊ≤¢Â±±„ÅÑ„Å¶„ÄÅ„ÅÑ„Åè„ÇâÊçï„Åæ„Åà„Å¶„ÇÇ‰∏ÄÂêë„Å´Ê∏õ„Çâ„Å™„ÅÑ„ÅÆ„Åß„Åô")}
    </div>
  );
}
