import type { InferGetStaticPropsType, NextPage } from "next";
import { readFile, readdir } from "fs/promises";
import path from "path";
import { createElement, useEffect, useMemo, useState } from "react";
import styles from "../styles/Home.module.css";

import {
  v1ResSentenceAnalyzed,
  Furigana,
  Xref,
  Word,
  Sense,
  ConjugatedPhrase,
  Particle,
} from "curtiz-japanese-nlp/interfaces";
import { AdjDeconjugated, Deconjugated } from "kamiya-codec";
import { ChinoParticle, ChinoParticlePicker, setup } from "../components/ChinoParticlePicker";
import { SimpleCharacter } from "curtiz-japanese-nlp/kanjidic";
import { groupBy } from "../utils";

export const getStaticProps = async () => {
  // might only print if you restart next dev server
  const parentDir = path.join(process.cwd(), "data");
  const jsons = (await readdir(parentDir)).filter((f) => f.toLowerCase().endsWith(".json"));
  console.log("ls", jsons);
  const sentences = await Promise.all(
    jsons.map((j) => readFile(path.join(parentDir, j), "utf8").then((x) => JSON.parse(x)))
  );
  const obj: SentenceDb = Object.fromEntries(sentences.map((s) => [s.sentence, s])); // TODO validate

  const particlesMarkdown = await readFile("all-about-particles.md", "utf8");
  const tags: NonNullable<v1ResSentenceAnalyzed["tags"]> = JSON.parse(await readFile("tags.json", "utf8"));
  return { props: { sentences: obj, particlesMarkdown, tags } };
};

interface Hit {
  startIdx: number;
  endIdx: number;
  word: Word;
  sense: number;
}

type AnnotatedConjugatedPhrase = ConjugatedPhrase & { selectedDeconj: ConjugatedPhrase["deconj"][0] };
type AnnotatedParticle = Particle & { chinoTag: string };
interface SentenceDbEntry {
  furigana: Furigana[][];
  dictHits: Hit[];
  conjHits: AnnotatedConjugatedPhrase[];
  particles: AnnotatedParticle[];
  kanjidic: v1ResSentenceAnalyzed["kanjidic"];
}
type SentenceDb = Record<string, { data: SentenceDbEntry }>;

interface FuriganaProps {
  vv: Furigana[][];
}
const Furigana = ({ vv }: FuriganaProps) => {
  return createElement(
    "span",
    null,
    ...vv.flatMap((v) =>
      v.map((f) =>
        typeof f === "string" ? (
          f
        ) : (
          <ruby>
            {f.ruby}
            <rt>{f.rt}</rt>
          </ruby>
        )
      )
    )
  );
};
function furiganaToString(f: Furigana | Furigana[] | Furigana[][]): string {
  if (Array.isArray(f)) {
    return f.map(furiganaToString).join("");
  }
  return typeof f === "string" ? f : f.ruby;
}

function renderKanji(w: Word) {
  return w.kanji.map((k) => k.text).join("ãƒ»");
}
function renderKana(w: Word) {
  return w.kana.map((k) => k.text).join("ãƒ»");
}
function renderWord(w: Word) {
  return `${renderKanji(w)} ã€Œ${renderKana(w)}ã€ (#${w.id})`;
}
function printXrefs(v: Xref[]) {
  return v.map((x) => x.join(",")).join(";");
}
function renderSenses(w: Word, tags: Record<string, string>): string[] {
  type Tag = string;
  type TagKey = {
    [K in keyof Sense]: Sense[K] extends Tag[] ? K : never;
  }[keyof Sense];
  const tagFields: Partial<Record<TagKey, string>> = {
    dialect: "ğŸ—£",
    field: "ğŸ€„ï¸",
    misc: "âœ‹",
  };
  return w.sense.map(
    (sense, n) =>
      sense.gloss.map((gloss) => gloss.text).join("/") +
      (sense.related.length ? ` (ğŸ‘‰ ${printXrefs(sense.related)})` : "") +
      (sense.antonym.length ? ` (ğŸ‘ˆ ${printXrefs(sense.antonym)})` : "") +
      Object.entries(tagFields)
        .map(([k, v]) =>
          sense[k as TagKey].length ? ` (${v} ${sense[k as TagKey].map((k) => tags[k]).join("; ")})` : ""
        )
        .join("")
  );
}
function range(start: number, endExclusive: number, step = 1) {
  const ret: number[] = [];
  if (step === 0) {
    return ret;
  } else if (step > 0) {
    for (let i = start; i < endExclusive; i += step) {
      ret.push(i);
    }
  } else {
    for (let i = start; i > endExclusive; i += step) {
      ret.push(i);
    }
  }
  return ret;
}
function upsertIfNew<X, Y>(v: X[], newx: X, key: (x: X) => Y) {
  const newy = key(newx);
  for (const [i, x] of v.entries()) {
    const y = key(x);
    if (y === newy) {
      if (x === newx) {
        return v;
      }
      const copy = v.slice();
      copy[i] = newx;
      return copy;
    }
  }
  return v.concat(newx);
}
function circleNumber(n: number): string {
  const circledNumbers = "â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©â‘ªâ‘«â‘¬â‘­â‘®â‘¯â‘°â‘±â‘²â‘³ã‰‘ã‰’ã‰“ã‰”ã‰•ã‰–ã‰—ã‰˜ã‰™ã‰šã‰›ã‰œã‰ã‰ã‰ŸãŠ±ãŠ²ãŠ³ãŠ´ãŠµãŠ¶ãŠ·ãŠ¸ãŠ¹ãŠºãŠ»ãŠ¼ãŠ½ãŠ¾ãŠ¿";
  return circledNumbers[n] || "" + n;
}

function renderDeconjugation(d: AdjDeconjugated | Deconjugated) {
  if ("auxiliaries" in d) {
    return `${d.auxiliaries.join(" + ")} + ${d.conjugation}`;
  }
  return d.conjugation;
}

const clozeToKey = (x: Pick<ConjugatedPhrase, "startIdx" | "endIdx">): string => `${x.startIdx}-${x.endIdx}`;

interface AnnotateProps {
  line: string;
  sentencesDb: SentenceDb;
}
// This should not work in static-generated output, ideally it won't exist.
const HELPER_URL = "http://localhost:3010";
const Annotate = ({ line, sentencesDb }: AnnotateProps) => {
  // This component will be called for lines that haven't been annotated yet.

  const [nlp, setNlp] = useState<v1ResSentenceAnalyzed | undefined>(undefined);
  const [furigana, setFurigana] = useState<Furigana[][]>(sentencesDb[line]?.data?.furigana || []);
  const [dictHits, setDictHits] = useState<Hit[]>(sentencesDb[line]?.data?.dictHits || []);
  const [conjHits, setConjHits] = useState<AnnotatedConjugatedPhrase[]>(sentencesDb[line]?.data?.conjHits || []);
  const [particles, setParticles] = useState<AnnotatedParticle[]>(sentencesDb[line]?.data?.particles || []);
  const [kanjidic, setKanjidic] = useState<undefined | SentenceDbEntry["kanjidic"]>(sentencesDb[line]?.data?.kanjidic);

  useEffect(() => {
    // Yes this will run twice in dev mode, see
    // https://reactjs.org/blog/2022/03/29/react-v18.html#new-strict-mode-behaviors
    if (!nlp) {
      (async function parse() {
        const req = await fetch(`${HELPER_URL}/sentence/${line}`, {
          headers: { Accept: "application/json" },
        });
        const data = await req.json();
        setNlp(data);
        setKanjidic(data.kanjidic);
        console.log("nlp", data);
      })();
    }
  }, []);

  useEffect(() => {
    saveDb(line, { dictHits, conjHits, particles, furigana, kanjidic: kanjidic || {} });
  }, [dictHits, conjHits, particles, furigana, kanjidic]);

  if (!nlp) {
    return <h2 lang={"ja"}>{furigana.length ? <Furigana vv={furigana} /> : line}</h2>;
  }
  if (!nlp.tags || !nlp.clozes) {
    throw new Error("tags/clozes expected");
  }

  const coveredHelper = (v: { startIdx: number; endIdx: number }[]) =>
    new Set(v.flatMap((o) => range(o.startIdx, o.endIdx)));
  const idxsCoveredDict = coveredHelper(dictHits);
  const idxsCoveredConj = coveredHelper(conjHits);
  // Skip the first morpheme, so we close the dict hits for the tail but not head
  const idxsCoveredConjForDict = new Set(conjHits.flatMap((o) => range(o.startIdx + 1, o.endIdx)));
  const wordIdsPicked = new Set(dictHits.map((o) => o.word.id));

  const hitkey = (x: Hit) => `${x.startIdx}/${x.endIdx}/${x.word.id}/${x.sense}`;
  const { tags, clozes } = nlp;
  const conjGroupedByStart = Array.from(groupBy(clozes.conjugatedPhrases, (o) => o.startIdx));

  return (
    <div>
      <h2 lang={"ja"}>
        <Furigana vv={nlp.furigana} />
      </h2>
      {furigana.length && kanjidic !== undefined ? (
        <button
          onClick={() => {
            setFurigana([]);
            setKanjidic(undefined);
          }}
        >
          Delete furigana + kanji
        </button>
      ) : (
        <button
          onClick={() => {
            setFurigana(nlp.furigana);
            setKanjidic(nlp.kanjidic);
          }}
        >
          Approve furigana + kanji
        </button>
      )}
      <details open>
        <summary>All annotations</summary>
        <details open>
          <summary>Selected dictionary entries</summary>
          <ul>
            {dictHits.map((h) => (
              <li>
                {h.startIdx}-{h.endIdx}: {renderKanji(h.word)} ã€Œ{renderKana(h.word)}ã€ {circleNumber(h.sense)}{" "}
                {renderSenses(h.word, tags)[h.sense]}{" "}
                <button
                  onClick={() => {
                    const removeKey = hitkey(h);
                    setDictHits(dictHits.filter((h) => hitkey(h) !== removeKey));
                  }}
                >
                  Remove
                </button>
              </li>
            ))}
          </ul>
          <details>
            <AddDictHit
              furigana={nlp.furigana}
              submit={(hit) => setDictHits(upsertIfNew(dictHits, hit, hitkey))}
              sentencesDb={sentencesDb}
            />
            <summary>Add custom dictionary hit</summary>
          </details>
        </details>
        <details open>
          <summary>All conjugated phrases found</summary>
          <ol>
            {conjGroupedByStart.map(([startIdx, conjugatedPhrases]) => (
              <li>
                <details open={!idxsCoveredConj.has(startIdx)}>
                  <summary>{conjugatedPhrases[0].morphemes[0].literal[0]}â€¦</summary>
                  <ol>
                    {conjugatedPhrases.map((foundConj) => (
                      <li>
                        {foundConj.cloze.cloze} = <Furigana vv={[foundConj.lemmas[0]]} />{" "}
                        {
                          <select
                            value={(function () {
                              const key = clozeToKey(foundConj);
                              const x = conjHits.find((dec) => clozeToKey(dec) === key)?.selectedDeconj;
                              if (!x) return "0";
                              const renderedX = renderDeconjugation(x);
                              return foundConj.deconj.findIndex((p) => renderDeconjugation(p) === renderedX) + 1;
                            })()}
                            onChange={(e) => {
                              const idx = +e.target.value;
                              const phraseKey = clozeToKey(foundConj);
                              setConjHits(
                                idx
                                  ? upsertIfNew(
                                      conjHits,
                                      { ...foundConj, selectedDeconj: foundConj.deconj[idx - 1] },
                                      clozeToKey
                                    )
                                  : conjHits.filter((p) => clozeToKey(p) !== phraseKey)
                              );
                            }}
                          >
                            <option value="0">Pick one of {foundConj.deconj.length}</option>
                            {foundConj.deconj.map((dec, idx) => {
                              const readable = renderDeconjugation(dec);
                              return (
                                <option key={idx + 1} value={idx + 1}>
                                  {readable}
                                </option>
                              );
                            })}
                          </select>
                        }
                      </li>
                    ))}
                  </ol>
                </details>
              </li>
            ))}
          </ol>
        </details>
        <details open>
          <summary>All particles found</summary>
          <ol>
            {clozes.particles.map((foundParticle) => {
              return (
                <li>
                  <sub>{foundParticle.cloze.left}</sub>
                  {foundParticle.cloze.cloze}
                  <sub>{foundParticle.cloze.right}</sub>:{" "}
                  {foundParticle.morphemes.map((m) => m.partOfSpeech.join("/")).join(", ")}{" "}
                  {foundParticle.chino.length && (
                    <ChinoParticlePicker
                      particleNumbers={foundParticle.chino.map(([i]) => i)}
                      currentValue={particles.find((x) => clozeToKey(foundParticle) === clozeToKey(x))?.chinoTag}
                      onChange={(e) =>
                        setParticles(
                          e
                            ? upsertIfNew(particles, { ...foundParticle, chinoTag: e }, clozeToKey)
                            : particles.filter((x) => clozeToKey(x) !== clozeToKey(foundParticle))
                        )
                      }
                    />
                  )}
                </li>
              );
            })}
          </ol>
        </details>
        <details open>
          <summary>All dictionary entries matched</summary>
          <ol>
            {nlp.hits.map(
              (scoreHits, outerIdx) =>
                scoreHits.results.length > 0 && (
                  <li key={outerIdx} value={outerIdx}>
                    <ol>
                      {scoreHits.results.map((res) => {
                        const open = range(scoreHits.startIdx, res.endIdx).some(
                          (x) => !(idxsCoveredConjForDict.has(x) || idxsCoveredDict.has(x))
                        );
                        const anyPickedClass = res.results.find((hit) => wordIdsPicked.has(hit.wordId))
                          ? ""
                          : styles["no-hit-picked"];
                        return (
                          <li>
                            <details open={open}>
                              <summary className={anyPickedClass}>
                                {typeof res.run === "string" ? res.run : res.run.cloze}
                              </summary>
                              <ol>
                                {res.results.map((hit) => {
                                  if (!hit.word) {
                                    throw new Error("word expected");
                                  }
                                  const word = hit.word;
                                  return (
                                    <li>
                                      <sup>{hit.search}</sup> {renderWord(hit.word)}
                                      <ol>
                                        {renderSenses(hit.word, tags).map((s, senseIdx) => (
                                          <li>
                                            <>
                                              {s}{" "}
                                              <button
                                                onClick={() => {
                                                  setDictHits(
                                                    upsertIfNew(
                                                      dictHits,
                                                      {
                                                        startIdx: scoreHits.startIdx,
                                                        endIdx: res.endIdx,
                                                        word: word,
                                                        sense: senseIdx,
                                                      },
                                                      hitkey
                                                    )
                                                  );
                                                }}
                                              >
                                                Pick
                                              </button>
                                            </>
                                          </li>
                                        ))}
                                      </ol>
                                    </li>
                                  );
                                })}
                              </ol>
                            </details>
                          </li>
                        );
                      })}
                    </ol>
                  </li>
                )
            )}
          </ol>
        </details>
        {Object.keys(nlp.kanjidic).length ? (
          <details open>
            <summary>Kanji</summary>
            <Kanjidic hits={nlp.kanjidic} />
          </details>
        ) : (
          <></>
        )}
      </details>
    </div>
  );
};

interface RenderSentenceProps {
  line: string;
  sentencesDb: SentenceDb;
  tags: Record<string, string>;
  chinoMap: Map<string, ChinoParticle>;
}
const RenderSentence = ({ line, sentencesDb, tags, chinoMap }: RenderSentenceProps) => {
  const { furigana = [], dictHits = [], conjHits = [], particles = [], kanjidic = {} } = sentencesDb[line]?.data || {};
  const numKanji = Object.keys(kanjidic).length;
  const className = furigana.length === 0 ? "no-furigana" : "";
  return (
    <div>
      <h2 className={styles[className]} lang={"ja"}>
        {furigana.length ? <Furigana vv={furigana} /> : line}
      </h2>
      <ul>
        {dictHits.length ? (
          <li key="d">
            <ul>
              {dictHits.map((h) => (
                <li>
                  {h.startIdx}-{h.endIdx}: {renderKanji(h.word)} ã€Œ{renderKana(h.word)}ã€ {circleNumber(h.sense)}{" "}
                  {renderSenses(h.word, tags)[h.sense]} <sub>{h.word.id}</sub>
                </li>
              ))}
            </ul>
          </li>
        ) : (
          <></>
        )}
        {conjHits.length ? (
          <li key="c">
            <ul>
              {conjHits.map((foundConj) => (
                <li>
                  {foundConj.cloze.cloze} = <Furigana vv={[foundConj.lemmas[0]]} />{" "}
                  {(function () {
                    const key = clozeToKey(foundConj);
                    const x = conjHits.find((dec) => clozeToKey(dec) === key)?.selectedDeconj;
                    if (!x) return "0";
                    const renderedX = renderDeconjugation(x);
                    const found = (foundConj.deconj as Ugh<typeof foundConj.deconj>).find(
                      (p) => renderDeconjugation(p) === renderedX
                    );
                    if (found) {
                      return renderDeconjugation(found);
                    }
                  })()}
                </li>
              ))}
            </ul>
          </li>
        ) : (
          <></>
        )}
        {particles.length ? (
          <li key="p">
            <ul>
              {particles.map((foundParticle) => {
                return (
                  <li>
                    <>
                      <sub>{foundParticle.cloze.left}</sub>
                      {foundParticle.cloze.cloze}
                      <sub>{foundParticle.cloze.right}</sub>:{" "}
                      {foundParticle.morphemes.map((m) => m.partOfSpeech.join("/")).join(", ")}{" "}
                      {foundParticle.chino.length &&
                        chinoMap.get(particles.find((x) => clozeToKey(foundParticle) === clozeToKey(x))?.chinoTag || "")
                          ?.fullLine}
                    </>
                  </li>
                );
              })}
            </ul>
          </li>
        ) : (
          <></>
        )}
        {numKanji ? (
          <li key="k">
            <details>
              <summary>{numKanji} kanji</summary>
              <Kanjidic hits={kanjidic} />
            </details>
          </li>
        ) : (
          <></>
        )}
      </ul>
    </div>
  );
};

interface KanjidicProps {
  hits: v1ResSentenceAnalyzed["kanjidic"];
}
function Kanjidic({ hits }: KanjidicProps) {
  return (
    <ul>
      {Object.values(hits).map((dic) => (
        <li>
          {renderKanjidicRoot(dic)}
          <ul>
            {dic.dependencies.map((root) => (
              <KanjidicChild root={root} />
            ))}
          </ul>
        </li>
      ))}
    </ul>
  );
}
interface KanjidicChildProps {
  root: v1ResSentenceAnalyzed["kanjidic"][string]["dependencies"][number];
}
function KanjidicChild({ root }: KanjidicChildProps) {
  if (!root.nodeMapped) {
    return <li>{root.node}</li>;
  }
  return (
    <li>
      {renderKanjidicRoot(root.nodeMapped)}
      <ul>
        {root.children.map((child) => (
          <KanjidicChild root={child} />
        ))}
      </ul>
    </li>
  );
}
function renderKanjidicRoot(k: SimpleCharacter) {
  const ret = `${k.literal} ã€Œ${k.readings.join("ãƒ»")}ã€ ${k.meanings.join("; ")}`;
  if (k.nanori.length) {
    return ret + ` (å: ${k.nanori.join("ãƒ»")})`;
  }
  return ret;
}

async function saveDb(line: string, { dictHits, conjHits, particles, furigana, kanjidic }: SentenceDbEntry) {
  const post =
    dictHits.length > 0 ||
    conjHits.length > 0 ||
    particles.length > 0 ||
    furigana.length > 0 ||
    Object.keys(kanjidic).length > 0;
  const data: SentenceDbEntry = { dictHits, conjHits, particles, furigana, kanjidic };
  const res = await fetch(`${HELPER_URL}/sentence`, {
    method: post ? "POST" : "DELETE",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      sentence: line,
      data,
    }),
  });
  if (!res.ok) {
    console.error(`${res.status} ${res.statusText}`);
  } else {
    console.log("saved");
  }
}

// https://stackoverflow.com/questions/70843127#comment128628953_70843200
type Ugh<T> = (T extends (infer X)[] ? X : never)[];

export default function HomePage({
  sentences: sentencesDb,
  particlesMarkdown,
  tags,
}: InferGetStaticPropsType<typeof getStaticProps>) {
  const chinoMap = setup(particlesMarkdown).nestedMap;

  const [annotating, setAnnotating] = useState(new Set<string>());

  const s = (s: string) =>
    !annotating.has(s) ? (
      <>
        <RenderSentence key={s} line={s} sentencesDb={sentencesDb} tags={tags} chinoMap={chinoMap} />
        <button onClick={() => setAnnotating(new Set(annotating).add(s))}>Annotate above</button>
      </>
    ) : (
      <>
        <Annotate key={s} line={s} sentencesDb={sentencesDb} />
        <button onClick={() => setAnnotating(new Set([...annotating].filter((x) => x !== s)))}>Done annotating</button>
      </>
    );
  return (
    <div>
      <p>Here's the first line of Oshiri Tantei #3.</p>
      {s("ã‚ã‚‹æ—¥ã®æœæ—©ãã€ã‚¸ãƒªãƒªãƒªãƒ³ã¨ãŠã—ã‚ŠãŸã‚“ã¦ã„äº‹å‹™æ‰€ã®é›»è©±ãŒé³´ã‚Šã¾ã—ãŸã€‚")}
      <p>And the second.</p>
      {s("ãƒ–ãƒ©ã‚¦ãƒ³ã¯çœ ã„ç›®ã‚’ã“ã™ã‚ŠãªãŒã‚‰å—è©±å™¨ã‚’å–ã‚Šã¾ã—ãŸ")}
      {s("ã‚ã—ã˜ã‚ƒï¼")}
      {s("ä»Šã™ããƒ¯ãƒ³ã‚³ãƒ­è­¦å¯Ÿç½²ã«æ¥ã¦ãã‚ŒãŸã¾ãˆï¼")}
      {s("ã›ã£ã‹ã¡ãªã‚“ã ã‹ã‚‰")}
      <p>We're done with the first page! Page 3 in the bookâ€”</p>
      {s("ãƒ•ãƒ ã€ã©ãªãŸã‹ã‚‰ã§ã—ãŸã‹ï¼Ÿ")}
      {s("ã€Œãƒãƒ«ãƒãƒ¼ã‚ºç½²é•·ã§ã™ã€")}
      {s("ã€Œãƒ¯ãƒ³ã‚³ãƒ­è­¦å¯Ÿç½²ã¾ã§æ¥ã¦ãã‚Œã£ã¦ã€ãŠã—ã‚ŠãŸã‚“ã¦ã„ã¨ãƒ–ãƒ©ã‚¦ãƒ³ã¯æ€¥ã„ã§å‡ºã‹ã‘ã‚‹æº–å‚™ã‚’ã—ã¾ã—ãŸ")}
      <p>ãƒãƒ• is SFX for his hat hitting his head.</p>
      <p>Onto page 4!!</p>
      {s("éšæ®µã‚’é™ã‚Šã‚‹ã¨éˆ´ãŒã€ãƒ©ãƒƒã‚­ãƒ¼ã‚­ãƒ£ãƒƒãƒˆã€ã®å‰ã§ãƒã‚¤ã‚¯ã‚’ç£¨ã„ã¦ã„ã¾ã—ãŸ")}
      {s("ã€ŒãŠã¯ã‚ˆã†ã€‚æœã£ã±ã‚‰ã‹ã‚‰ä»•äº‹ã‹ï¼Ÿã€ã¨éˆ´ãŒå°‹ã­ã¾ã—ãŸ")}
      {s("ã€Œãƒ¯ãƒ³ã‚³ãƒ­è­¦å¯Ÿç½²ã«è¡Œãã‚“ã§ã™ã€‚æœã”é£¯ã‚‚ã¾ã ã ã£ãŸã®ã«ã€")}
      {s("ãƒ–ãƒ©ã‚¦ãƒ³ã¯æ¬ ä¼¸ã‚’ã—ãªãŒã‚‰ç­”ãˆã¾ã—ãŸ")}
      {s("ã‹ã£ã“ã„ã„ãƒã‚¤ã‚¯ã§ã™ã­")}
      {s("ã ã‚ï¼Ÿãƒã‚¤ãƒˆæ›ã‘æŒã¡ã—ã¦è²·ã£ãŸã‚“ã ")}
      <p>Page 5</p>
      {s("ãŠã—ã‚ŠãŸã‚“ã¦ã„ã¨ãƒ–ãƒ©ã‚¦ãƒ³ã¯ãƒ¯ãƒ³ã‚³ãƒ­è­¦å¯Ÿç½²ã«ç€ãã¾ã—ãŸ")}
      {s("ã€ŒãŠå¾…ã¡ã—ã¦ãŠã‚Šã¾ã—ãŸï¼ã€")}
      {s("ã‚¬ã‚¿ã‚¤ã®è‰¯ã„åˆ‘äº‹ãŸã¡ãŒå‡ºè¿ãˆã¾ã™")}
      {s("ã•ãã€ã“ã¡ã‚‰ã¸ã€‚ãƒãƒ«ãƒãƒ¼ã‚ºç½²é•·ãŒãŠå¾…ã¡ã§ã™")}
      {s("ï¼“å€‹ã®ãŠã—ã‚Šã‚’æ¢ã›")}
      {s("å¸‚æ°‘ã®å®‰å…¨")}
      {s("å®‰å…¨ãƒŠãƒ³ãƒãƒ¼ãƒ¯ãƒ³")}
      {s("ãƒ¯ãƒ³ãƒ€ãƒ•ãƒ«ãªç”ºã¸")}
      <p>Picking up the pace, are we?</p>
      {s("å¤§ããç«‹æ´¾ãªæœºã®å‰ã«ãƒãƒ«ãƒãƒ¼ã‚ºç½²é•·ãŒã¡ã‚‡ã“ã‚“ã¨åº§ã£ã¦ã„ã¾ã™")}
      {s("å¾…ã£ã¦ãŠã£ãŸãï¼")}
      {s("ãŠã—ã‚ŠãŸã‚“ã¦ã„ãã‚“ã€‚ãƒ–ãƒ©ã‚¦ãƒ³ã‚‚ä¹…ã—ã¶ã‚Šã˜ã‚ƒãª")}
      {s("ã€Œãƒ•ãƒ ã€æ—©é€ŸãŠé›»è©±ã‚’ãŠä¼ºã„ã—ã¾ã—ã‚‡ã†ã‹ã€")}
      {s("çŠ¬")}
      {s("ã‚¹ã‚¿ãƒƒ")}
      {s("ãƒ–ãƒ©ãƒƒã‚¯ã‚·ãƒ£ãƒ‰ãƒ¼å›£ã¨ã„ã†é¢å€’ãªå¥´ã‚‰ãŒç¾ã‚ã‚Œã¦ãªã€‚")}
      {s("è«¸å›ã€è©³ã—ã„èª¬æ˜ã‚’é ¼ã‚€")}
      {s("ãƒ–ãƒ©ãƒƒã‚¯ã‚·ãƒ£ãƒ‰ãƒ¼å›£ã¯é›†å›£ã§ç›—ã¿ã‚’è¡Œã†çªƒç›—å›£ã§ãŠé‡‘æŒã¡ã®å®¶ã‚’ç‹™ã„ã€å®¶ã«ã‚ã‚‹ç‰©å…¨ã¦æ ¹ã“ããç›—ã‚“ã§ã„ãã¾ã™ã€‚")}
      <p>
        Learner's note: see Kamiya <em>Handbook of Japanese Verbs</em>, page 54, for more on the "Vconj + Vconj + masu"
        form.
      </p>
      {s("ãƒ¡ãƒ³ãƒãƒ¼ã¯æ²¢å±±ã„ã¦ã€ã„ãã‚‰æ•ã¾ãˆã¦ã‚‚ä¸€å‘ã«æ¸›ã‚‰ãªã„ã®ã§ã™")}
      {s("ãã—ã¦ã¤ã„ã«ã“ã®ç”ºã«ã‚‚ãƒ–ãƒ©ãƒƒã‚¯ã‚·ãƒ£ãƒ‰ãƒ¼å›£ãŒã‚„ã£ã¦ããŸã‚ˆã†ãªã®ã§ã™")}
      {s("ãƒ–ãƒ©ãƒƒã‚¯ã‚·ãƒ£ãƒ‰ãƒ¼ãƒ¡ãƒ³ãƒ‰ãƒ¼")}
      {s("ãã†ãªã‚“ã˜ã‚ƒï¼")}
      {s("ãƒ–ãƒ©ãƒƒã‚¯ã‚·ãƒ£ãƒ‰ãƒ¼å›£ã¨æ€ã‚ã‚Œã‚‹ã‚„ã¤ã‚’æ•ã¾ãˆãŸã‚“ã˜ã‚ƒã‚ˆï¼")}
      {s("ãƒ¯ãƒ³ã‚³ãƒ­è­¦å¯Ÿç½²ã§ä¸€ç•ªå‰ãã¦å„ªç§€ãªã“ã®ã‚ã—ãŒãªï¼")}
      {s("ãã‚Œã¯æ˜¨æ—¥ã®ã“ã¨ã˜ã‚ƒã£ãŸ")}
      <p>(Above, we think ã˜ã‚ƒã£ãŸ is ã +past tense, with the usual way the chief replaces ã  with ã˜ã‚ƒ.)</p>
      {s("ã‚ªãƒ¬ãƒ³ã‚¸ãŒ")}
      {s("ä¸¸ã„ã‚‚ã®ï¼")}
      {s("ãƒ“ã‚·ãƒ£ãƒ¼")}
      {s("å™¨ç‰©æå£Šã§ç¾è¡ŒçŠ¯é€®æ•ã˜ã‚ƒ")}
      {s("ã‚ã—ã®ä¸¸ã„ã‚‚ã®")}
      {s("ãƒãƒ«ãƒãƒ¼ã‚ºç½²é•·ã¯å¾—æ„ã’ãªé¡”ã§ãˆã£ã¸ã‚“ã¨å’³æ‰•ã„ã‚’ã—ã¾ã—ãŸ")}
      {s("ã»ã¨ã‚“ã©è¨€ã„ãŒã‹ã‚Šãªã‚“ã˜ã‚ƒ")}
      {s("ä¸¸ã„ç‰©ã®æ„›ç€ãŒã™ã”ã„ã‚“ã§ã™")}
      {s("è¦‹å¢ƒãŒãªããªã‚‹ã‚“ã§ã™")}
      {s("ç§˜")}
      {s("ãƒ•ãƒ ã€ãªãœãƒ–ãƒ©ãƒƒã‚¯ã‚·ãƒ£ãƒ‰ãƒ¼å›£ã®ãƒ¡ãƒ³ãƒãƒ¼ã ã¨åˆ†ã‹ã£ãŸã®ã§ã™ã‹ï¼Ÿ")}
      {s("ã€Œã“ã‚Œã‚’è¦‹ã¦ãã‚Œã„ã€")}
      {s("ãƒãƒ«ãƒãƒ¼ã‚ºç½²é•·ã¯ã€ãŠã—ã‚ŠãŸã‚“ã¦ã„ã«è³‡æ–™ã‚’æ¸¡ã—ã¾ã—ãŸ")}
      {s("è³‡æ–™ã¯ã»ã‹ã®ç”ºã§æ•ã‚‰ãˆã‚‰ã‚ŒãŸãƒ–ãƒ©ãƒƒã‚¯ã‚·ãƒ£ãƒ‰ãƒ¼å›£ã®ãƒ¡ãƒ³ãƒãƒ¼ãŸã¡ã®å†™çœŸã§ã—ãŸ")}
      {s("ãŠã—ã‚ŠãŸã‚“ã¦ã„ã¯ä¸€ç›®è¦‹ã¦")}
      {s("ãƒ•ãƒ ã€ãã†ã„ã†ã“ã¨ã§ã™ã‹")}
      {s("ä½•ã‹ã‚ã‹ã£ãŸã‚“ã§ã™ã‹ï¼Ÿ")}
      {s("ãƒ•ãƒ ã€ãƒ¡ãƒ³ãƒãƒ¼ãŸã¡ã«ã¯ä¸€ã¤å…±é€šã—ã¦ã„ã‚‹ã‚‚ã®ãŒã‚ã‚Šã¾ã™ã€‚ãã‚Œã¯ãªã‚“ã§ã—ã‚‡ã†ï¼Ÿ")}
      {s("ãƒ–ãƒ©ãƒƒã‚¯ã‚·ãƒ£ãƒ‰ãƒ¼å›£é€®æ•è€…ãƒªã‚¹ãƒˆ")}
      {s("ãã†ã§ã™ã€‚ãƒšãƒ³ãƒ€ãƒ³ãƒˆã§ã™ã­ã€‚")}
      {s("ã€Œãƒšãƒ³ãƒ€ãƒ³ãƒˆã¯ãƒ–ãƒ©ãƒƒã‚¯ã‚·ãƒ£ãƒ‰ãƒ¼å›£ã®ãƒ¡ãƒ³ãƒãƒ¼ã¨ã„ã†ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã®ã§ã¯ãªã„ã§ã™ã‹ï¼Ÿã€")}
      {s("ãƒãƒ«ãƒãƒ¼ã‚ºç½²é•·ãŒæ•ã¾ãˆãŸæ–¹ã‚‚ãƒšãƒ³ãƒ€ãƒ³ãƒˆã‚’ã¤ã‘ã¦ã„ãŸã®ã§ã™ã­")}
      {s("ã•ã™ãŒã˜ã‚ƒï¼")}
      {s("è©±ãŒæ—©ã„ã‚ã„ï¼")}
      <p>The above is an idiom: "easy to get to the point" (page 68 in Akiyama and Akiyama)</p>
      {s("ã“ã‚ŒãŒãã‚„ã¤ã®ã¤ã‘ã¦ã„ãŸãƒšãƒ³ãƒ€ãƒ³ãƒˆã˜ã‚ƒ")}
      {s("ãƒ–ãƒ©ãƒƒã‚¯ã‚·ãƒ£ãƒ‰ãƒ¼å›£ã¯ã“ã®ãƒšãƒ³ãƒ€ãƒ³ãƒˆã‚’ã¤ã‘ã¦ã„ã‚‹ã®ã‹")}
      <p>We've finished page 12!</p>
    </div>
  );
}

function searchSentencesDbForJmdictId(db: SentenceDb, id: string) {
  if (!id) {
    return undefined;
  }
  for (const key in db) {
    const hit = db[key].data.dictHits.find((h) => h.word.id === id);
    if (hit) {
      return hit?.word;
    }
  }
}
interface AddDictHit {
  furigana: Furigana[][];
  submit: (hit: Hit) => void;
  sentencesDb: SentenceDb;
}
function AddDictHit({ furigana, submit, sentencesDb }: AddDictHit) {
  const [start, setStart] = useState(0);
  const [end, setEnd] = useState(furigana.length);
  const [wordId, setWordId] = useState("");
  const [sense, setSense] = useState(0);
  const word = useMemo(() => (wordId ? searchSentencesDbForJmdictId(sentencesDb, wordId) : undefined), [wordId]);

  return (
    <p>
      <>
        Tag from{" "}
        <MorphemesSelector
          furigana={furigana}
          submit={(s, e) => {
            setStart(s);
            setEnd(e);
          }}
        />{" "}
        <input type="text" placeholder="Jmdict word id" value={wordId} onChange={(e) => setWordId(e.target.value)} />{" "}
        {wordId && word ? (
          <>
            {renderWord(word)}{" "}
            <select value={sense} onChange={(e) => setSense(+e.target.value)}>
              {word.sense.map((s, i) => (
                <option key={i} value={i}>
                  {s.gloss.map((g) => g.text).join("/")}
                </option>
              ))}
            </select>{" "}
          </>
        ) : (
          <>waiting for valid ID</>
        )}{" "}
        <button
          disabled={!(word && sense >= 0)}
          onClick={() => {
            if (word && sense >= 0) {
              const res = { startIdx: start, endIdx: end, word: word, sense };
              submit(res);
            }
          }}
        >
          Submit
        </button>
      </>
    </p>
  );
}

interface MorphemesSelectorProps {
  furigana: Furigana[][];
  submit: (startIdx: number, endIdx: number) => void;
}
function MorphemesSelector({ furigana, submit }: MorphemesSelectorProps) {
  const [start, setStart] = useState(0);
  const [end, setEnd] = useState(furigana.length);
  useEffect(() => submit(start, end), [start, end]);
  return (
    <>
      <select
        value={start}
        onChange={(e) => {
          const x = +e.target.value;
          setStart(x);
          setEnd(Math.max(end, x + 1));
        }}
      >
        {range(0, furigana.length).map((n) => (
          <option key={n} value={n}>
            {furigana[n].map(furiganaToString).join("")}â€¦
          </option>
        ))}
      </select>{" "}
      to{" "}
      <select value={end} onChange={(e) => setEnd(+e.target.value)}>
        {range(start + 1, furigana.length + 1).map((n) => (
          <option key={n} value={n}>
            {furigana
              .slice(start, n)
              .flatMap((v) => v.map(furiganaToString))
              .join("")}
          </option>
        ))}
      </select>
    </>
  );
}
